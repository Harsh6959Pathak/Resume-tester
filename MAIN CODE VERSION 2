!pip install gradio sentence-transformers nltk scikit-learn pandas torch

import gradio as gr
import pandas as pd
import re
import torch
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import time

# Download stopwords once
nltk.download('stopwords')

# Load pretrained model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_name = 'sentence-transformers/all-MiniLM-L6-v2'
bert_model = SentenceTransformer(model_name).to(device)

# Clean and preprocess text
def clean_text(text):
    if pd.isna(text):
        return ""
    text = text.lower()
    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)
    stop_words = set(stopwords.words('english'))
    filtered = ' '.join([word for word in text.split() if word not in stop_words])
    return filtered

# Resume ranking function
def rank_resumes(file, job_desc):
    start_time = time.time()
    if file is None:
        return "‚ö†Ô∏è Please upload a CSV file!"

    try:
        df = pd.read_csv(file.name, encoding='latin1')

        required_cols = ['skills', 'career_objective', 'degree_names', 'major_field_of_studies', 'positions', 'responsibilities']
        missing = [col for col in required_cols if col not in df.columns]
        if missing:
            return f"‚ö†Ô∏è Missing columns: {missing}"

        # Clean text columns and combine
        for col in required_cols:
            df[col] = df[col].apply(clean_text)

        df['combined_text'] = df[required_cols].agg(' '.join, axis=1)

        # Clean job description
        jd_clean = clean_text(job_desc)

        # Compute embeddings
        resume_embeds = bert_model.encode(df['combined_text'].tolist(), convert_to_tensor=True, device=device)
        jd_embed = bert_model.encode([jd_clean], convert_to_tensor=True, device=device)

        # Cosine similarity scores
        scores = cosine_similarity(jd_embed.cpu().numpy(), resume_embeds.cpu().numpy())[0]
        df['similarity_score'] = scores

        # Rank top 5 resumes
        top_df = df.nlargest(5, 'similarity_score').reset_index(drop=True)

        elapsed = round(time.time() - start_time, 2)

        # Prepare output table markdown
        output = f"### üìå Top 5 Resume Matches (Processed in {elapsed} seconds)\n\n"
        output += "| Rank | Similarity Score | Resume Preview (first 200 chars) |\n"
        output += "|-------|-----------------|----------------------------------|\n"

        for i, row in top_df.iterrows():
            preview = row['combined_text'][:200] + ("..." if len(row['combined_text']) > 200 else "")
            output += f"| {i+1} | {row['similarity_score']:.4f} | {preview} |\n"

        return output

    except Exception as e:
        return f"‚ö†Ô∏è Error: {str(e)}"

# Gradio interface
with gr.Blocks() as demo:
    gr.Markdown("# üìÑ Resume Tester and Ranking App")

    with gr.Row():
        resume_file = gr.File(label="Upload Resumes CSV")
        job_description = gr.Textbox(label="Job Description", lines=5, placeholder="Enter job description here...")

    submit = gr.Button("Rank Resumes")

    result = gr.Markdown()

    submit.click(rank_resumes, inputs=[resume_file, job_description], outputs=result)

demo.launch(share=True)
